{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c252bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeviceDir\n",
    "\n",
    "DIR, RESULTS_DIR = DeviceDir.get_directory()\n",
    "device, NUM_PROCESSORS = DeviceDir.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d839f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, Reddit\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch_geometric.datasets import WikipediaNetwork\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.typing import Adj, SparseTensor\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.datasets import Reddit, Reddit2, Flickr, Yelp, AmazonProducts, PPI,  OGB_MAG,  FakeDataset, Amazon,Coauthor,HeterophilousGraphDataset, CitationFull\n",
    "from torch_geometric.utils import homophily\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.utils import add_random_edge\n",
    "\n",
    "def fix_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "fix_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8ccf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_mask(data, train=0.4, val=0.3, test=0.3, random_state=False):\n",
    "\n",
    "    if isinstance(data.x, SparseTensor):\n",
    "        N = data.x.size(0)\n",
    "        data.num_nodes = N\n",
    "    else:\n",
    "        N = data.x.shape[0]\n",
    "\n",
    "    indexs = list(range(N))\n",
    "\n",
    "    if random_state:\n",
    "        train_index, test_index = train_test_split(indexs, test_size=val+test)\n",
    "        val_index, test_index = train_test_split(test_index, test_size=test/(val+test))\n",
    "    else:\n",
    "        train_index, test_index = train_test_split(indexs, test_size=val+test, random_state=1)\n",
    "        val_index, test_index = train_test_split(test_index, test_size=test/(val+test), random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "    train_mask = torch.zeros(N, dtype=bool)\n",
    "    train_mask[train_index]=True\n",
    "    val_mask = torch.zeros(N, dtype=bool)\n",
    "    val_mask[val_index]=True\n",
    "    test_mask = torch.zeros(N, dtype=bool)\n",
    "    test_mask[test_index]=True\n",
    "\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687f266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def adj_feature(data):    \n",
    "    adj_mat = torch.zeros((data.num_nodes,data.num_nodes))\n",
    "    edges = data.edge_index.t()\n",
    "    adj_mat[edges[:,0], edges[:,1]] = 1\n",
    "    adj_mat[edges[:,1], edges[:,0]] = 1\n",
    "    \n",
    "#     return adj_mat\n",
    "    \n",
    "#     n_components = data.x.shape[1]\n",
    "    n_components = min(256, data.x.shape[1], data.num_nodes)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    x = svd.fit_transform(adj_mat)\n",
    "    \n",
    "    x = torch.Tensor(x)\n",
    "    x.shape    \n",
    "    \n",
    "    return x\n",
    "\n",
    "# data.x = torch.cat((data.x, adj_feature(data)), dim=1)\n",
    "# data.x = adj_feature(data)\n",
    "# print(data.x.shape)\n",
    "# data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed5ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import KarateClub, Reddit, Reddit2, Flickr, Yelp, AmazonProducts, PPI,  OGB_MAG,  FakeDataset, Amazon,Coauthor,HeterophilousGraphDataset,LINKXDataset\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "def load_dataset(dataset_name):\n",
    "    \n",
    "    DATASET_NAME = dataset_name\n",
    "    \n",
    "    if dataset_name == \"karate\":\n",
    "        dataset = KarateClub()\n",
    "    elif dataset_name == \"moon\":\n",
    "        from ipynb.fs.full.Moon import MoonDataset\n",
    "        dataset = MoonDataset(n_samples=100, degree=4, train=0.2, h = 0.2)\n",
    "    elif dataset_name == \"SmallCora\":\n",
    "        dataset = Planetoid(root=DIR+'/tmp/Cora', name='Cora')\n",
    "    elif dataset_name in [\"Cora\", \"Cora_ML\", \"CiteSeer\", \"DBLP\", \"PubMed\"]:\n",
    "        dataset = CitationFull(root=DIR+'/tmp/Citation/'+dataset_name, name=dataset_name)\n",
    "    elif dataset_name == 'Amazon-ratings':\n",
    "        dataset = HeterophilousGraphDataset(root=DIR+'/tmp/amazon_ratings', name = dataset_name)\n",
    "#     elif dataset_name == 'Roman-empire':\n",
    "#         from torch_geometric.datasets import LINKXDataset\n",
    "#         dataset = LINKXDataset(DIR+'/tmp/Roman_empire', dataset_name)\n",
    "    elif dataset_name == \"Reddit\":\n",
    "        dataset = Reddit(root=DIR+'/tmp/Reddit')\n",
    "    elif dataset_name == 'penn94':\n",
    "        from torch_geometric.datasets import LINKXDataset\n",
    "        dataset = LINKXDataset(root=DIR+'/tmp/LINKX', name=dataset_name)\n",
    "    elif dataset_name == 'wiki':\n",
    "        from torch_geometric.datasets import WikiCS\n",
    "        dataset = WikiCS(root=DIR+'/tmp/WikiCS')\n",
    "    elif dataset_name == 'Photo':\n",
    "        dataset = Amazon(root=DIR+'/tmp/Photo', name='Photo')\n",
    "    elif dataset_name == 'CiteSeer':\n",
    "        dataset = Planetoid(root=DIR+'/tmp/CiteSeer', name=DATASET_NAME)\n",
    "    elif dataset_name == 'CS':\n",
    "        dataset = Coauthor(root=DIR+'/tmp/CS', name = DATASET_NAME)\n",
    "    elif dataset_name == 'Physics':\n",
    "        dataset = Coauthor(root=DIR+'/tmp/Physics', name = DATASET_NAME)\n",
    "    elif dataset_name == 'Minesweeper':\n",
    "        dataset   = HeterophilousGraphDataset(root=DIR+'/tmp/Mine',name=dataset_name)\n",
    "#     elif dataset_name == 'pokec':\n",
    "#         print(\"HELLOWROLD \")\n",
    "    elif dataset_name == 'ogbn-proteins':\n",
    "        dataset = PygNodePropPredDataset(name='ogbn-proteins', root=DIR+'/tmp/ogbn-proteins')\n",
    "        data = dataset[0]\n",
    "        data.node_species = None\n",
    "        data.y = data.y.to(torch.float)\n",
    "\n",
    "        # Initialize features of nodes by aggregating edge features.\n",
    "        row, col = data.edge_index\n",
    "        data.x = scatter(data.edge_attr, col, dim_size=data.num_nodes, reduce='sum')\n",
    "        labels = data.y.argmax(dim=1)\n",
    "        data.y = labels\n",
    "        \n",
    "        return dataset, data\n",
    "    elif dataset_name == 'squirrel':\n",
    "        dataset = WikipediaNetwork(root=DIR+'/tmp/squirrel', name='Squirrel')\n",
    "    elif dataset_name == 'AmazonProducts':\n",
    "        dataset = AmazonProducts(root=DIR+'/tmp/AmazonProducts')\n",
    "    else:        \n",
    "        from ipynb.fs.full.Dataset import get_data\n",
    "        data, dataset = get_data(dataset_name, log=False, h_score = False, split_no = 0)\n",
    "        \n",
    "        return dataset, data\n",
    "    \n",
    "    #print(dataset)\n",
    "    data = dataset[0]\n",
    "    #print(data)\n",
    "    \n",
    "    if torch.min(data.y)<0:        \n",
    "        data.y = data.y-torch.min(data.y)    \n",
    "\n",
    "        \n",
    "    return dataset, data\n",
    "\n",
    "\n",
    "def LOAD_DATASET(DIR, dataset_name):    \n",
    "    \n",
    "    DATASET_NAME = dataset_name\n",
    "    dataset, data = load_dataset(dataset_name)\n",
    "\n",
    "    try:\n",
    "        if \"val_mask\" not in data.__dict__['_store']:    \n",
    "            data = train_val_test_mask(data, train=0.2, val=0.4, test=0.4)\n",
    "    except:    \n",
    "        try:\n",
    "            if \"val_mask\" not in data.__dict__['data']:\n",
    "                data = train_val_test_mask(data, train=0.2, val=0.4, test=0.4)            \n",
    "        except:\n",
    "            None\n",
    "\n",
    "    if len(data.train_mask.shape) > 1 and len(data.val_mask.shape) > 1 and len(data.test_mask.shape) > 1:    \n",
    "        try:\n",
    "            split_index = 2\n",
    "            data.train_mask = data.train_mask[:,split_index]\n",
    "            data.val_mask = data.val_mask[:,split_index]\n",
    "            data.test_mask = data.test_mask[:,split_index]\n",
    "\n",
    "        except:        \n",
    "            data = train_val_test_mask(data, train=0.2, val=0.4, test=0.4)\n",
    "\n",
    "    if data.is_undirected() == False:\n",
    "        data.edge_index = to_undirected(data.edge_index, reduce = \"mean\")\n",
    "\n",
    "\n",
    "    if dataset_name in ['Squirrel','Chameleon','Amazon-ratings','reed98']:\n",
    "        x = adj_feature(data)\n",
    "        data.x = torch.cat((data.x, x), dim=1)\n",
    "\n",
    "\n",
    "    num_classes = int(max(data.y)+1)\n",
    "    num_features = data.x.shape[1]\n",
    "\n",
    "#     print(\"\"\"Stats.....\"\"\")\n",
    "#     print(f'Dataset: {dataset}:')\n",
    "#     print('======================')\n",
    "#     print(f'Number of graphs: {len(dataset)}')\n",
    "#     print(f'Number of features: {num_features}')\n",
    "#     print(f'Number of classes: {num_classes}')\n",
    "#     print()\n",
    "#     print(data)\n",
    "#     print('===========================================================================================================')\n",
    "\n",
    "#     # Gather some statistics about the graph.\n",
    "#     print(f'Number of nodes: {data.num_nodes}')\n",
    "#     print(f'Number of edges: {data.num_edges}')\n",
    "#     print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "#     print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "#     print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "#     print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "#     print(f'Has self-loops: {data.has_self_loops()}')\n",
    "#     print(f'Is undirected: {data.is_undirected()}')\n",
    "    \n",
    "    print(f'{dataset_name} N: {data.num_nodes} E: {data.num_edges} F: {num_features} C: {num_classes} d: {data.num_edges / data.num_nodes:.2f}' , end=' ')\n",
    "    print(f'lr: {int(data.train_mask.sum()) / data.num_nodes:.2f} i: {data.has_isolated_nodes()} s: {data.has_self_loops()} u: {data.is_undirected()}')\n",
    "    \n",
    "    \n",
    "    return data, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504a9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmallCora N: 2708 E: 10556 F: 1433 C: 7 d: 3.90 lr: 0.05 i: False s: False u: True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data, dataset = LOAD_DATASET(DIR, 'SmallCora')\n",
    "    data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e85b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My py311cu117pyg200 Kernel)",
   "language": "python",
   "name": "py311cu117pyg200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
