{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9dfae7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url\n",
    "\n",
    "\n",
    "class Reddit2(InMemoryDataset):\n",
    "\n",
    "    url = 'https://docs.google.com/uc?export=download&id={}&confirm=t'\n",
    "\n",
    "    adj_full_id = '1sncK996BM5lpuDf75lDFqCiDZyErc1c2'\n",
    "    feats_id = '1ZsHaJ0ussP1W722krmEIp_8pwKAoi5b3'\n",
    "    class_map_id = '1JF3Pjv9OboMNYs2aXRQGbJbc4t_nDd5u'\n",
    "    role_id = '1nJIKd77lcAGU4j-kVNx_AIGEkveIKz3A'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "    \n",
    "    @property\n",
    "    def num_node_features(self):\n",
    "        return self.data[0]['x'].shape[1]\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return max(self.data[0]['y']).item()+1\n",
    "\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url.format(self.adj_full_id), self.raw_dir)\n",
    "        os.rename(path, osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "\n",
    "        path = download_url(self.url.format(self.feats_id), self.raw_dir)\n",
    "        os.rename(path, osp.join(self.raw_dir, 'feats.npy'))\n",
    "\n",
    "        path = download_url(self.url.format(self.class_map_id), self.raw_dir)\n",
    "        os.rename(path, osp.join(self.raw_dir, 'class_map.json'))\n",
    "\n",
    "        path = download_url(self.url.format(self.role_id), self.raw_dir)\n",
    "        os.rename(path, osp.join(self.raw_dir, 'role.json'))\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'), allow_pickle = True)\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        x = np.load(osp.join(self.raw_dir, 'feats.npy'))\n",
    "        x = torch.from_numpy(x).to(torch.float)\n",
    "\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0982acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIR='/scratch/gilbreth/das90/Dataset/'\n",
    "# dataset = Reddit2(root=DIR+'Reddit2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76662b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acef1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b2d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My py311cu117pyg200 Kernel)",
   "language": "python",
   "name": "py311cu117pyg200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
